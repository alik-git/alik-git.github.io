<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Ali Kuwajerwala </title> <meta name="author" content="Ali Kuwajerwala"> <meta name="description" content="Ali's wesbite, with links and everything. "> <meta name="keywords" content="ali, kuwajerwala, robotics, computer, science, artificial, intelligence, engineer, academic-website, portfolio-website"> <meta property="og:site_name" content="Ali Kuwajerwala"> <meta property="og:type" content="website"> <meta property="og:title" content="Ali Kuwajerwala | about"> <meta property="og:url" content="https://alik-git.github.io/"> <meta property="og:description" content="Ali's wesbite, with links and everything. "> <meta property="og:image" content="/assets/img/prof_pic.jpg"> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="about"> <meta name="twitter:description" content="Ali's wesbite, with links and everything. "> <meta name="twitter:image" content="/assets/img/prof_pic.jpg"> <meta name="twitter:site" content="@alihkw_"> <meta name="twitter:creator" content="@alihkw_"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A4%96&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://alik-git.github.io/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/podcast/">podcast </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Ali</span> Kuwajerwala </h1> <p class="desc">Robotics and AI, Researcher and Engineer</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," sizes="(min-width: 800px) 231.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/prof_pic.jpg?ae05c89d06647266c7cc1eb3852cdb30" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic_long-480.webp 480w,/assets/img/prof_pic_long-800.webp 800w,/assets/img/prof_pic_long-1400.webp 1400w," sizes="(min-width: 800px) 231.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/prof_pic_long.jpg?d62a0f12ba92eeb38711c6cf785140ea" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic_long.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="clearfix"> <p>Hi there! üòÉ</p> <p>My name is Ali and I‚Äôm a soon-to-be-graduating master‚Äôs student at <a href="https://mila.quebec/" rel="external nofollow noopener" target="_blank">Mila</a> &amp; the <a href="https://diro.umontreal.ca/accueil/" rel="external nofollow noopener" target="_blank">University of Montr√©al</a>, supervised by <a href="https://liampaull.ca/" rel="external nofollow noopener" target="_blank">Prof. Liam Paull</a> at the <a href="http://montrealrobotics.ca/" rel="external nofollow noopener" target="_blank">Montreal Robotics and Embodied AI Lab</a>. I‚Äôm quite passionate about AI and robotics research, and engaged in the quest to understand and simulate intelligence. The <a href="https://concept-fusion.github.io/" rel="external nofollow noopener" target="_blank">ConceptFusion</a> and <a href="https://concept-graphs.github.io/" rel="external nofollow noopener" target="_blank">ConceptGraphs</a> papers which I worked on during my masters are small steps towards this goal.</p> <p><strong>I am currently actively seeking out work opportunities for both full-time roles and internships. I‚Äôm open to relocation and non-robotics roles, what matters to me is working on important problems! You can take a look at my resume <a href="/cv.pdf">here</a>. If you‚Äôd like to get in touch, please don‚Äôt hesitate to email me at alihusein.kuwajerwala@x, x=umontreal.ca, or on Twitter/LinkedIn!</strong></p> <p>Previously, I interned at the <a href="https://www.amazon.jobs/en/teams/alexa-ai" rel="external nofollow noopener" target="_blank">Alexa AI</a> team at <a href="https://www.aboutamazon.com/news/amazon-ai" rel="external nofollow noopener" target="_blank">Amazon</a>, where I worked on using large language models for querying databases. In between my undergrad and master‚Äôs I was a student researcher at the <a href="https://rvl.cs.toronto.edu/" rel="external nofollow noopener" target="_blank">Robot, Vision and Learning Lab</a> at the <a href="https://www.utoronto.ca/" rel="external nofollow noopener" target="_blank">University of Toronto</a> supervised by <a href="http://www.cs.toronto.edu/~florian/" rel="external nofollow noopener" target="_blank">Prof. Florian Shkurti</a> where I worked on <a href="https://arxiv.org/abs/2110.07668" rel="external nofollow noopener" target="_blank">visual navigation for mobile robots</a>. I‚Äôve also worked in software engineering roles at <a href="https://epson.ca/about-us" rel="external nofollow noopener" target="_blank">Epson</a> and <a href="https://www.liquidanalytics.com/" rel="external nofollow noopener" target="_blank">Liquid Analytics</a>.</p> <p>My undergrad was at the <a href="https://www.utoronto.ca/" rel="external nofollow noopener" target="_blank">Univeristy of Toronto</a> where I studied CS &amp; Math, and also worked as a Teaching Assistant. During my time there I was co-founder of the <a href="https://utmrobotics.com/" rel="external nofollow noopener" target="_blank">UTM Robotics Club</a>, and a recipient of the <a href="https://www.nserc-crsng.gc.ca/Students-Etudiants/UG-PC/USRA-BRPC_eng.asp" rel="external nofollow noopener" target="_blank">NSERC Undergraduate Student Research Award</a>.</p> <p>I‚Äôve also worked on a couple of fun coding projects which you can look at via my <a href="https://github.com/alik-git" rel="external nofollow noopener" target="_blank">github profile</a>.</p> <p>When I‚Äôm not staring at a screen all day, you can find me training jiu-jitsu, listening to audiobooks and podcasts, doodling, and/or chatting with wonderful people on my <a href="/podcast">podcast</a>. ‚úåÔ∏è</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Feb 01, 2024</th> <td> <a href="https://concept-graphs.github.io/" rel="external nofollow noopener" target="_blank">ConceptGraphs</a> was accepted to ICRA! üå∏ </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 05, 2023</th> <td> <a href="https://concept-fusion.github.io/" rel="external nofollow noopener" target="_blank">ConceptFusion</a> was accepted to RSS! üèõÔ∏è </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 16, 2022</th> <td> The <a href="https://arxiv.org/abs/2110.07668" rel="external nofollow noopener" target="_blank">Equivariant Representations paper</a> was <a href="https://ieeexplore.ieee.org/document/9811885" rel="external nofollow noopener" target="_blank">accepted</a> to <a href="https://www.icra2022.org/" rel="external nofollow noopener" target="_blank">ICRA 2022</a>! üéâ </td> </tr> <tr> <th scope="row" style="width: 20%">Mar 31, 2020</th> <td> Received the <a href="https://www.nserc-crsng.gc.ca/students-etudiants/ug-pc/usra-brpc_eng.asp" target="_blank" rel="external nofollow noopener">NSERC Undergraduate Student Research Award</a>! ü§ì </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 06, 2019</th> <td> Co-founded the <a href="https://www.instagram.com/utm_robotics" target="_blank" rel="external nofollow noopener">UTM Robotics Club</a> as Head of Operations! ü¶æ </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/conceptgraphs_splash-480.webp 480w,/assets/img/publication_preview/conceptgraphs_splash-800.webp 800w,/assets/img/publication_preview/conceptgraphs_splash-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/conceptgraphs_splash.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="conceptgraphs_splash.gif" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="gu2023conceptgraphs" class="col-sm-8"> <div class="title">ConceptGraphs: Open-Vocabulary 3D Scene Graphs for Perception and Planning</div> <div class="author"> Alihusein Kuwajerwala ,¬†Qiao Gu ,¬†Sacha Morin , and <span class="more-authors" title="click to view 13 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '13 more authors' ? 'Krishna Murthy Jatavallabhula, Bipasha Sen, Aditya Agarwal, Corban Rivera, William Paul, Kirsty Ellis, Rama Chellappa, Chuang Gan, Celso Miguel Melo, Joshua B. Tenenbaum, Antonio Torralba, Florian Shkurti, Liam Paull' : '13 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">13 more authors</span> </div> <div class="periodical"> 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://concept-graphs.github.io/assets/pdf/2023-ConceptGraphs.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://concept-graphs.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=5Q7kQgIAAAAJ&amp;citation_for_view=5Q7kQgIAAAAJ:2osOgNQ5qMEC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>For robots to perform a wide variety of tasks, they require a 3D representation of the world that is semantically rich, yet compact and efficient for task-driven perception and planning. Recent approaches have attempted to leverage features from large vision-language models to encode semantics in 3D representations. However, these approaches tend to produce maps with per-point feature vectors, which do not scale well in larger environments, nor do they contain semantic spatial relationships between entities in the environment, which are useful for downstream planning. In this work, we propose ConceptGraphs, an open-vocabulary graph-structured representation for 3D scenes. ConceptGraphs is built by leveraging 2D foundation models and fusing their output to 3D by multi-view association. The resulting representations generalize to novel semantic classes, without the need to collect large 3D datasets or finetune models. We demonstrate the utility of this representation through a number of downstream planning tasks that are specified through abstract (language) prompts and require complex reasoning over spatial and semantic concepts.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">gu2023conceptgraphs</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{ConceptGraphs: Open-Vocabulary 3D Scene Graphs for Perception and Planning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kuwajerwala, Alihusein and Gu, Qiao and Morin, Sacha and Jatavallabhula, Krishna Murthy and Sen, Bipasha and Agarwal, Aditya and Rivera, Corban and Paul, William and Ellis, Kirsty and Chellappa, Rama and Gan, Chuang and de Melo, Celso Miguel and Tenenbaum, Joshua B. and Torralba, Antonio and Shkurti, Florian and Paull, Liam}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{International Conference on Robotics and Automation (ICRA)}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2302.07241}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{2osOgNQ5qMEC}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/conceptfusion_splash-480.webp 480w,/assets/img/publication_preview/conceptfusion_splash-800.webp 800w,/assets/img/publication_preview/conceptfusion_splash-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/conceptfusion_splash.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="conceptfusion_splash.gif" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="conceptfusion2023" class="col-sm-8"> <div class="title">ConceptFusion: Open-set Multimodal 3D Mapping</div> <div class="author"> Krishna Murthy Jatavallabhula ,¬†Alihusein Kuwajerwala ,¬†Qiao Gu , and <span class="more-authors" title="click to view 13 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '13 more authors' ? 'Mohd Omama, Tao Chen, Shuang Li, Ganesh Iyer, Soroush Saryazdi, Nikhil Keetha, Ayush Tewari, Joshua B. Tenenbaum, Celso Miguel Melo, Madhava Krishna, Liam Paull, Florian Shkurti, Antonio Torralba' : '13 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">13 more authors</span> </div> <div class="periodical"> 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://concept-fusion.github.io/assets/pdf/2023-ConceptFusion.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://concept-fusion.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=5Q7kQgIAAAAJ&amp;citation_for_view=5Q7kQgIAAAAJ:d1gkVwhDpl0C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Building 3D maps of the environment is central to robot navigation, planning, and interaction with objects in a scene. Most existing approaches that integrate semantic concepts with 3D maps largely remain confined to the closed-set setting: they can only reason about a finite set of concepts, pre-defined at training time. Further, these maps can only be queried using class labels, or in recent work, using text prompts. We address both these issues with ConceptFusion, a scene representation that is (1) fundamentally open-set, enabling reasoning beyond a closed set of concepts and (ii) inherently multimodal, enabling a diverse range of possible queries to the 3D map, from language, to images, to audio, to 3D geometry, all working in concert. ConceptFusion leverages the open-set capabilities of today‚Äôs foundation models pre-trained on internet-scale data to reason about concepts across modalities such as natural language, images, and audio. We demonstrate that pixel-aligned open-set features can be fused into 3D maps via traditional SLAM and multi-view fusion approaches. This enables effective zero-shot spatial reasoning, not needing any additional training or finetuning, and retains long-tailed concepts better than supervised approaches, outperforming them by more than 40% margin on 3D IoU. We extensively evaluate ConceptFusion on a number of real-world datasets, simulated home environments, a real-world tabletop manipulation task, and an autonomous driving platform. We showcase new avenues for blending foundation models with 3D open-set multimodal mapping.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">conceptfusion2023</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/ARXIV.2302.07241}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2302.07241}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Jatavallabhula, Krishna Murthy and Kuwajerwala, Alihusein and Gu, Qiao and Omama, Mohd and Chen, Tao and Li, Shuang and Iyer, Ganesh and Saryazdi, Soroush and Keetha, Nikhil and Tewari, Ayush and Tenenbaum, Joshua B. and de Melo, Celso Miguel and Krishna, Madhava and Paull, Liam and Shkurti, Florian and Torralba, Antonio}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{ConceptFusion: Open-set Multimodal 3D Mapping}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Robotics: Science and Systems (RSS)}</span><span class="p">,</span>
  <span class="na">google_scholar_id</span> <span class="p">=</span> <span class="s">{d1gkVwhDpl0C}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">copyright</span> <span class="p">=</span> <span class="s">{Creative Commons Attribution Share Alike 4.0 International}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="https://scholar.google.com/citations?user=5Q7kQgIAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/alik-git" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/alihkw" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://twitter.com/alihkw_" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> <a href="https://wikipedia.org/wiki/User:Ali.hkw" title="Wikipedia" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-wikipedia-w"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fa-solid fa-square-rss"></i></a> </div> <div class="contact-note">Feel free to reach out via email, twitter, or linkedin. </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2025 Ali Kuwajerwala. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: October 21, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?da39b660470d1ba6e6b8bf5f37070b6e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>